# HDFS

##### HDFS 특징 (목표)

```
- 장애 복구

	* 장애의 빠른시간 대처 / 복구 / 복제데이터
	
	=> 분산서버는 다양한 장애 상황(네트워크 장애, 하드웨어 장애, 디스크 장애)에 놓일 수 있다. 
	디스크 장애시에는 데이터 복구가 불가능한 경우가 발생한다.
	HDFS는 이러한 장애를 감지하여 분산 서버간에 상태를 체크할 수 있도록 한다.
	이를 통해 장애를 미리 인지하여 대처할 수 있고, 데이터 복제를 통해 데이터 복구가 불가능한 경우를 미	 연에 방지할 수 있다.
	
- 스트리밍 방식의 데이터 접근

	* 요청을 빠른 시간내에 처리하는 것보다는 동일한 시간 내에 처리
	
	=> HDFS는 스트리밍 방식으로 데이터에 접근하기 때문에 특정 위치의 정보를 읽는데는 적합하지 않다.
	대신, 처음 부터 끝까지 모든 데이터를 읽는 많은 양의 데이터를 처리하는데 유리하다.

- 대용량 데이터 저장

	* 하나의 파일에 수 기가바이트에서 테라바이트까지 저장 가능

- 데이터 무결성

	* 무결성원칙 - 변조를 할 수 없다. 
	  append는 가능하다.
	
	=> HDFS는 한번 저장한 데이터는 수정할 수 없고, 읽기만 가능해 데이터의 무결성을 유지한다.
	(파일 이동,삭제,복사는 가능하다.)
	RDBMS와 사용용도에 차이가 있다.
```



##### HDFS 아키텍처



![HDFS분산](https://user-images.githubusercontent.com/49560745/62588872-4928e200-b902-11e9-8363-5ae0db5a009c.PNG)

```
블록 구조 파일 시스템

- HDFS에 저장하는 파일은 특정 크기(통상 64MB)의 블록으로 나눠저 분산된 서버에 저장된다
 = > 큰 규모의 데이터 저장 가능
 
블록 크기가 64MB인 이유

- 디스크 시크 타임 감소
- 네임노드가 유지하는 메타데이터의 크기 감소
- 클라이언트와 네임노드의 통신 감소

=> 블록은 크기가 64MB 경계를 넘어서면 두 번째 블록이 필요하다. (블록 당 최대 64MB 저장가능)
   HDFS는 대용량의 데이터를 처리하기 위함인데 
   예를 들어, 1000MB 파일을 처리한다고 할 때, 4k라는 작은 단위로 블록 크기를 사용하게 되면
   256,000개의 요청이 필요하다.(네트워크 요청이 많아져 오버헤드 발생)
   따라서, 가능한 최대 블록 크기(64MB)를 사용함으로써 오버헤드 및 비용 발생을 줄일 수 있다.
   
```

##### 네임노드와 데이터노드

```
네임노드 : 마스터
데이터노드 : 슬레이브
(maters slaves (in conf) 와는 다르게 생각하자)
보조 네임노드 : 메타데이터 BACKUP

파일 읽기/쓰기요청 : 클라이언트 -> HDFS 클러스터
파일 제어요청 : 클라이언트 -> 네임노드 -> HDFS 클러스터
파일 읽기/쓰기 응답 : HDFS 클러스터 -> 클라이언트
하트비트 전송 : alive함 + 블록의 목록을 데이터노드가 -> 네임노드로 전송하는 것
블록관리 : 네임노드는 장애가 발생한 데이터노드를 발견하면 해당 데이터노드의 블록을 새로운 데이터노드로 복제

클라이언트 요청 접수 : 클라이언트가 HDFS에 접근하려면 반드시 네임노드에 먼저 접속해야 
					한다 
					
					
					name : 메타정보
					data : 물리적으로 big data의 블록이 저장되는 공간
					tmp : 임시적으로 (backup의 느낌(?))
```



##### 파일 저장 요청

```
클라이언트 -----> DistributedFileSystem -------> DFSClient -------> 네임노드
		스트림요청                     스트림생성          유효성검사요청
```



##### 블록조회

![블록조회](https://user-images.githubusercontent.com/49560745/62590143-6364bf00-b906-11e9-9ac6-44429387ac42.PNG)



##### 보조네임노드

```
- 네임노드는 메타데이터를 메모리에서 처리
- 메모리에만 데이터를 유지할 경우 유실 위험 존재
- 따라서 HDFS는 editslog 와 fsimage라는 두개의 파일을 생성하여 이를 극복


fsimage : 최신정보 (딱 하나의 정보)
editslog : log가 계속 쌓인다

* 메타데이터 : 데이터의 데이터
			=> 데이터의 형식이 다양화되고 있는 상황에서 원하는 정보를 빠르게 찾아나가기 위해 ( 하드디스크 용량 / 데이터 용량 / 목록 )
```



##### HDFS 명령어

```
- 파일 용량 확인
hadoop fs -du

- 삭제
hadoop fs -rmr /mydir

- 파일생성
hadoop fs -touchz filename

- 휴지통비우기 (hadoop은 삭제하면 휴지통으로~)
hadoop fs -expunge

```





